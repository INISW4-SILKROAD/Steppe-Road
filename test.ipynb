{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.galata import Galata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Galata(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('galata.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    print(model('dataset/57/57.jpg', torch.Tensor([\n",
    "            [\n",
    "            0.54,\n",
    "            0.4,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.06,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0\n",
    "            ]]).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'galata.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/csv/fraction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('datasets/flexibility_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from PIL import Image \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,pre = clip.load(\"ViT-B/32\", device='cuda:0')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/json/flexibility_train.json')as f:\n",
    "    j = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = [pre(Image.open(i['img'])).unsqueeze(0)for i in j]\n",
    "portion = [i['portion']for i in j]\n",
    "label = [i['label'] -1 for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = {}\n",
    "for i in['softness', 'smoothness', 'flexibility', 'thickness']:\n",
    "    for j in ['train']:\n",
    "        with open(f'data/json/{i}_{j}.json')as f:\n",
    "            j = json.load(f)\n",
    "        j = [{'img':im, 'portion':i['portion'], 'label' :i['label']}for i in j for im in i['img']]\n",
    "        image = torch.stack([pre(Image.open(i['img']))for i in j])\n",
    "        portion = torch.Tensor([i['portion']for i in j])\n",
    "        label = torch.Tensor([i['label'] -1 for i in j])\n",
    "        print(image.shape)\n",
    "\n",
    "        torch.save(TensorDataset(image, portion, label), f'datasets/{i}_train.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in['softness', 'smoothness', 'flexibility', 'thickness']:\n",
    "    for j in ['test']:\n",
    "        with open(f'data/json/{i}_{j}.json')as f:\n",
    "            j = json.load(f)\n",
    "        image = torch.stack([pre(Image.open(i['img']))for i in j])\n",
    "        portion = torch.Tensor([i['portion']for i in j])\n",
    "        label = torch.Tensor([i['label'] -1 for i in j])\n",
    "        print(image.shape)\n",
    "        torch.save(TensorDataset(image, portion, label), f'datasets/{i}_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'img':im, 'portion':i['portion'], 'label' :i['label']}for i in j for im in i['img']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([torch.load('datasets/dataset_flexibility_train.pth')[0][0], torch.load('datasets/dataset_flexibility_train.pth')[1][0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagebind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
